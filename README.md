本项目构建了一个完整的 Titanic 生还预测建模流程，涵盖数据清洗、特征工程、模型训练、调参和预测。
在建模过程中，我将数据清洗步骤模块化，并通过 sklearn pipeline 统一管理，避免数据泄漏。
我对多种模型进行了对比实验，包括 Logistic Regression、Gaussian Naive Bayes 和 KNN。
虽然 KNN 在验证集上表现较好，但在线上测试中泛化能力较弱，说明泛化效果不佳。
同时，我尝试了特征选择与降维方法（卡方检验、LDA），发现其在该数据分布下并未带来性能提升，反而削弱了模型效果。

在 Titanic 生还预测任务中，不同模型的性能受其内在假设与数据特性的匹配程度影响显著。
高斯朴素贝叶斯因强独立与分布假设限制了性能上限；
逻辑回归在随机切分验证中表现良好，但线性决策边界对测试集分布变化较为敏感；
KNN 在高维稀疏特征空间中出现明显过拟合，泛化能力不足；
基于单变量统计的特征选择方法（如卡方检验）和分布假设严格的降维方法（LDA）均未能有效提升模型性能。

总得来说：这个模型只是把流程走通，但是整个实施过程并不科学、高效，在算法选择和数据处理上都存在问题，正确的做法应该是：
1️⃣ 根据数据特性选择算法
（样本量、离散/连续特征比例、噪声、分布稳定性）

2️⃣ 根据算法特性处理特征或构造新特征
（是否分箱、是否 one-hot、是否标准化、是否做交互）

3️⃣ 评估方式先于模型结论
（交叉验证、切分方式决定分数是否可信）

4️⃣ 用测试与预测差异判断是否过拟合
（测试高但预测低 → 模型或特征不稳）

5️⃣ 优化目标是稳定性与可解释性，而不是单次最高分
